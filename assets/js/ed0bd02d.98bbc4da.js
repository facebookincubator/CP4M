"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[513],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>f});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function c(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?c(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):c(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},c=Object.keys(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var r=a.createContext({}),g=function(e){var t=a.useContext(r),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=g(e.components);return a.createElement(r.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,c=e.originalType,r=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),p=g(n),u=o,f=p["".concat(r,".").concat(u)]||p[u]||m[u]||c;return n?a.createElement(f,i(i({ref:t},s),{},{components:n})):a.createElement(f,i({ref:t},s))}));function f(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var c=n.length,i=new Array(c);i[0]=u;var l={};for(var r in t)hasOwnProperty.call(t,r)&&(l[r]=t[r]);l.originalType=e,l[p]="string"==typeof e?e:o,i[1]=l;for(var g=2;g<c;g++)i[g]=n[g];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},1024:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>i,default:()=>m,frontMatter:()=>c,metadata:()=>l,toc:()=>g});var a=n(7462),o=(n(7294),n(3905));const c={sidebar_position:1},i="Connecting to Llama via Hugging Face",l={unversionedId:"llm-connections/connecting-llama-via-huggingface",id:"llm-connections/connecting-llama-via-huggingface",title:"Connecting to Llama via Hugging Face",description:"To connect CP4M to Llama via Hugging Face, you will need:",source:"@site/docs/llm-connections/connecting-llama-via-huggingface.md",sourceDirName:"llm-connections",slug:"/llm-connections/connecting-llama-via-huggingface",permalink:"/CP4M/docs/llm-connections/connecting-llama-via-huggingface",draft:!1,editUrl:"https://facebookincubator.github.io/CP4M/docs/intro/docs/llm-connections/connecting-llama-via-huggingface.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"LLM Connections",permalink:"/CP4M/docs/category/llm-connections"},next:{title:"Connecting to OpenAI",permalink:"/CP4M/docs/llm-connections/connecting-openai"}},r={},g=[{value:"Sign up for a Hugging Face account",id:"sign-up-for-a-hugging-face-account",level:2},{value:"Accessing the Llama model on Hugging Face",id:"accessing-the-llama-model-on-hugging-face",level:2},{value:"Deploying model using Inference API",id:"deploying-model-using-inference-api",level:2},{value:"Updating your CP4M config from Inference API",id:"updating-your-cp4m-config-from-inference-api",level:2}],s={toc:g},p="wrapper";function m(e){let{components:t,...c}=e;return(0,o.kt)(p,(0,a.Z)({},s,c,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"connecting-to-llama-via-hugging-face"},"Connecting to Llama via Hugging Face"),(0,o.kt)("p",null,"To connect CP4M to Llama via Hugging Face, you will need:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"A Hugging Face account"),(0,o.kt)("li",{parentName:"ol"},"Access to the Llama model from Meta")),(0,o.kt)("h2",{id:"sign-up-for-a-hugging-face-account"},"Sign up for a Hugging Face account"),(0,o.kt)("p",null,"Hugging Face is a platform that helps you build, deploy, and train machine learning models. You can sign up for an account ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/join"},"here"),"."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Hugging Face Home Page",src:n(5735).Z,width:"3076",height:"1764"})),(0,o.kt)("h2",{id:"accessing-the-llama-model-on-hugging-face"},"Accessing the Llama model on Hugging Face"),(0,o.kt)("p",null,"Hugging Face has a large repository of machine learning models for a variety of use cases accessible ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/models"},"here"),"."),(0,o.kt)("p",null,"You can search for the LLama model from Meta of your choice. For the purposes of this tutorial, we will be using the ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"},"LLama-2-7b-chat-hf model"),"."),(0,o.kt)("p",null,"In order to use the Llama model, you will need to accept the Llama 2 Community License Agreement on the ",(0,o.kt)("a",{parentName:"p",href:"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"},"model page"),"."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Gated model agremeent",src:n(7231).Z,width:"1148",height:"70"})),(0,o.kt)("p",null,"Once your account is approved, the model page will inform you that you have been granted access."),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Gated model access",src:n(4713).Z,width:"838",height:"86"})),(0,o.kt)("h2",{id:"deploying-model-using-inference-api"},"Deploying model using Inference API"),(0,o.kt)("p",null,"The fastest way to deploy Llama is through Hugging Face's serverless Inference API."),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Go to the ",(0,o.kt)("a",{parentName:"li",href:"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"},"Llama model page"),"."),(0,o.kt)("li",{parentName:"ol"},"On the top right, click on the ",(0,o.kt)("strong",{parentName:"li"},"Deploy")," dropdown button.")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Model Deploy",src:n(8090).Z,width:"3100",height:"1148"})),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"In the dropdown, click the ",(0,o.kt)("strong",{parentName:"li"},"Inference API (serverless)")," option. ",(0,o.kt)("em",{parentName:"li"},"Note: Using Inference API requires a ",(0,o.kt)("a",{parentName:"em",href:"https://huggingface.co/pricing"},"Hugging Face Pro subscription")),".")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Inference API First Time",src:n(8254).Z,width:"1800",height:"1040"})),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"On the new modal, click the ",(0,o.kt)("strong",{parentName:"li"},"Token")," dropdown then click ",(0,o.kt)("strong",{parentName:"li"},"+ New access token"),".")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Inference API New Token",src:n(3424).Z,width:"1796",height:"1038"})),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"On the access tokens page, click the ",(0,o.kt)("strong",{parentName:"li"},"New Token")," button.")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Access Token Page",src:n(1596).Z,width:"1096",height:"532"})),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Create a new access token with the ",(0,o.kt)("strong",{parentName:"li"},"Write")," permission.")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Create Access Token Modal",src:n(7998).Z,width:"770",height:"612"})),(0,o.kt)("ol",{start:7},(0,o.kt)("li",{parentName:"ol"},"Go back to the Model Deploy > Inference API page ",(0,o.kt)("a",{parentName:"li",href:"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf?inference_api=true"},"here"),". Your newly created access token should now be populated in the ",(0,o.kt)("strong",{parentName:"li"},"Token")," section.")),(0,o.kt)("h2",{id:"updating-your-cp4m-config-from-inference-api"},"Updating your CP4M config from Inference API"),(0,o.kt)("ol",{start:7},(0,o.kt)("li",{parentName:"ol"},"Copy and paste the ",(0,o.kt)("em",{parentName:"li"},"API_URL"),' on the Deploy Inference API modal to your CP4M config file in the "',"[","[",'plugins]] endpoint" entry. If you are using the Llama-2-7b-chat-hf model, it should be "',(0,o.kt)("a",{parentName:"li",href:"https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf%22"},'https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf"'),".")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Inference API code",src:n(7128).Z,width:"1452",height:"500"})),(0,o.kt)("ol",{start:8},(0,o.kt)("li",{parentName:"ol"},"Click ",(0,o.kt)("strong",{parentName:"li"},"Show API token"),'. Copy and paste this API token to your CP4M config file in the "',"[","[",'plugins]] api_key" entry.')),(0,o.kt)("p",null,"Congratulations! You have now successfully set up CP4M with Llama via Hugging Face."))}m.isMDXComponent=!0},1596:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-access-token-e4d4d34ecb02846e4ec5f05a7916548a.png"},7998:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-create-access-token-317a8b6bbb5d24c56febc5ce82cb0690.png"},4713:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-gated-model-access-6ee3943452e1cd7cef14073f79fb6c0b.png"},7231:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-gated-model-agreement-98f92b2c6156f9b0991d92c7ec5c2cd3.png"},5735:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-home-page-f1ff1ba3202940d82f458e3c2163bb6c.png"},7128:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-inference-api-code-b33d7c6b0b3db9fc0f8f743bb693319f.png"},8254:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-inference-api-first-time-2dcbfee12a2591bc62002c25e5cdcc1c.png"},3424:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-inference-api-new-token-533ad4694ba645b77dfdc216af5a11c3.png"},8090:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/hugging-face-model-deploy-6e774cf754f098f316d5556c6fe8bce5.png"}}]);